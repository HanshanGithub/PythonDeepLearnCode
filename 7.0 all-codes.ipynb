{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "492e0897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e9787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers\n",
    "input_tensor = Input(shape=(32,))\n",
    "dense = layers.Dense(32, activation='relu')\n",
    "output_tensor = dense(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90c0e10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 64)]              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_tensor, output_tensor)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479ec232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 错误示范\n",
    "# unrelated_input = Input(shape=(32,))\n",
    "# bad_model = model = Model(unrelated_input, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "405c48cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 11.6269\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 12.0554\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 13.1383\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 14.8951\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 17.4922\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 20.7004\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 24.3065\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 28.3470\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 33.1294\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 38.1569\n",
      "32/32 [==============================] - 0s 655us/step - loss: 41.6340\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "score = model.evaluate(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "348e4407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "\n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "question_input = Input(shape=(None,),dtype='int32', name='question')\n",
    "\n",
    "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1f9e78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 3s 53ms/step - loss: 6.2146 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 6.1968 - acc: 0.0470\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 6.1359 - acc: 0.0060\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 6.0533 - acc: 0.0040\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 5.9894 - acc: 0.0080\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 5.9165 - acc: 0.0090\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 43ms/step - loss: 5.8233 - acc: 0.0160\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 43ms/step - loss: 5.7177 - acc: 0.0220\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 5.6343 - acc: 0.0300\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 42ms/step - loss: 5.5496 - acc: 0.0280\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 2s 49ms/step - loss: 5.4869 - acc: 0.0340\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 5.4044 - acc: 0.0370\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 5.3346 - acc: 0.0420\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 5.2647 - acc: 0.0440\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 5.2027 - acc: 0.0530\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 5.1447 - acc: 0.0640\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 5.0835 - acc: 0.0730\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 5.0416 - acc: 0.0760\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 4.9720 - acc: 0.0890\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 4.9125 - acc: 0.0850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b6e8301f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1,text_vocabulary_size,size = (num_samples, max_length))\n",
    "\n",
    "question = np.random.randint(1,question_vocabulary_size,\n",
    "size = (num_samples,max_length))\n",
    "answers = np.random.randint(answer_vocabulary_size,size = (num_samples))\n",
    "answers = np_utils.to_categorical(answers,answer_vocabulary_size)\n",
    "\n",
    "model.fit([text,question],answers,epochs = 10,batch_size = 128)\n",
    "\n",
    "model.fit({'text':text,'question':question},answers,\n",
    "epochs = 10,batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9b5018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape = (None,),dtype = 'int32',name = 'posts')\n",
    "embedded_posts = layers.Embedding(256,vocabulary_size)(posts_input)\n",
    "\n",
    "x = layers.Conv1D(128,5,activation = 'relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256,5,activation = 'relu')(x)\n",
    "x = layers.Conv1D(256,5,activation = 'relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256,5,activation = 'relu')(x)\n",
    "x = layers.Conv1D(256,5,activation = 'relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128,activation = 'relu')(x)\n",
    "\n",
    "age_prediction = layers.Dense(1,name = 'age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups,\n",
    "activation = 'softmax',name = 'income')(x)\n",
    "gender_prediction = layers.Dense(1,activation = 'sigmoid',name = 'gender')(x)\n",
    "\n",
    "model = Model(posts_input,\n",
    "[age_prediction,income_prediction,gender_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4713aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码清单7-4多输出模型的编译选项:多重损失\n",
    "model.compile(optimizer = 'rmsprop',loss = ['mse','categorical_crossentropy','binary_crossentropy'])\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "              loss = {'age':'mse',\n",
    "                      'income':'categorical_crossentropy',\n",
    "                      'gender':'binary_crossentropy'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89999cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码清单7-5多输出模型的编译选项:(损失加权)\n",
    "# 代码意义同上\n",
    "model.compile(optimizer = 'rmsprop',loss = ['mse','categorical_crossentropy','binary_crossentropy'],loss_weights = [0.25,1.,10.])\n",
    "model.compile(optimizer = 'rmsprop',loss = {'age':'mse','income':'categorical_crossentropy','gender':'binary_crossentropy'},\n",
    "loss_weights = {'age':0.25,'income':1.,'gender':10.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f25725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 代码清单7-6将数据输入到多输出模型中\n",
    "# model.fit(posts,[age_targets,income_targets,gender_targets],\n",
    "# epochs = 10,batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bec6ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(posts,{'age':age_targets,'income':income_targets,'gender':gender_targets},epochs = 10,batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fd9f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P205\n",
    "# from keras import layers\n",
    "# import tensorflow as tf\n",
    "# # x = [1, 2, 3, 4] # 此处生成一个四维随机张量\n",
    "# x = tf.random.normal([4,32,32,3])\n",
    "# branch_a = layers.Conv2D(128,1,activation = 'relu',strides = 2)(x)\n",
    "# branch_b = layers.Conv2D(128,1,activation = 'relu')(x)\n",
    "# branch_b = layers.Conv2D(128,3,activation = 'relu',strides = 2)(branch_b)\n",
    "# branch_c = layers.AveragePooling2D(3,strides = 2)(x)\n",
    "# branch_c = layers.Conv2D(128,3,activation = 'relu')(branch_c)\n",
    "# branch_d = layers.Conv2D(128,1,activation = 'relu')(x)\n",
    "# branch_d = layers.Conv2D(128,3,activation = 'relu')(branch_d)\n",
    "# branch_d = layers.Conv2D(128,3,activation = 'relu',strides = 2)(branch_d)\n",
    "# output = layers.concatenate(\n",
    "# [branch_a,branch_b,branch_c,branch_d],axis = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aed6bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # P208\n",
    "# from keras import layers\n",
    "# from keras import Input\n",
    "# from keras.models import Model\n",
    "\n",
    "# lstm = layers.LSTM(32)\n",
    "\n",
    "# left_input = Input(shape = (None,128))\n",
    "# left__output = lstm(left_input)\n",
    "\n",
    "# right_input = Input(shape = (None,128))\n",
    "# right__output = lstm(right_input)\n",
    "\n",
    "# merged = layers.concatenate([left_output,right_output],axis = -1)\n",
    "# predictions = layers.Dense(1,activation = 'sigmoid')(merged)\n",
    "# model = Model([left_input,right_input],predictions)\n",
    "# model.fit([left_data,right_data],targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1d5e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P209\n",
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras import Input\n",
    "# from keras.models import Model\n",
    "# from keras import layers\n",
    "# from keras.layers import Dense, Input, BatchNormalization, Activation\n",
    "# from keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from sklearn.metrics import log_loss\n",
    "# from get_traffic_dataset import TrafficImageDataGenerator\n",
    "\n",
    "# xception_base = applications.Xception(weights = None,include_top = False)\n",
    "# left__input = Input(shape = (250,250,3))\n",
    "\n",
    "# right_input = Input(shape = (250,250,3))\n",
    "# left_features = xception_base(left_input)\n",
    "\n",
    "# right_input = xception_base(right_input)\n",
    "# merged_features = layers.concatenate([left_features,right_input],axis = -1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3f5ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P212\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "class ActivationLogger(keras.callbacks.Callback):\n",
    "    def set_model(self,model):\n",
    "        self.model = model\n",
    "        layer_outputs = [layer.output for layer in model.layers]\n",
    "        self.activations_model = keras.models.Model(model.input,layer_outputs)\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs = None):\n",
    "        if self.validation_data is None:\n",
    "            raiseRuntimeError('Requiresvalidation_data.')\n",
    "        validation_sample = self.validation_data[0][0:1]\n",
    "        activations = self.activations_model.predict(validation_sample)\n",
    "        f = open('activations_at_epoch_'+str(epoch) + '.npz','w')\n",
    "        np.savez(f,activations)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab5ccfae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 代码清单7-7使用了TensorBoard 的文本分类模型\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 2000\n",
    "max_len = 500\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words = max_features)\n",
    "x_train = sequence.pad_sequences(x_train,maxlen = max_len)\n",
    "x_test = sequence.pad_sequences(x_test,maxlen = max_len)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(max_features,128,input_length = max_len,name = 'embed'))\n",
    "model.add(layers.Conv1D(32,7,activation = 'relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32,7,activation = 'relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer = 'rmsprop',loss = 'binary_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18fb8aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 4s 23ms/step - loss: 0.5976 - acc: 0.6811 - val_loss: 0.4329 - val_acc: 0.8346A: 2s - loss: 0.70 - ETA: 0s - loss: 0.6358 - a\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.4356 - acc: 0.8483 - val_loss: 0.5035 - val_acc: 0.8472 0s - loss: 0.4365 - acc: 0.84\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.3852 - acc: 0.8795 - val_loss: 0.4911 - val_acc: 0.8694\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.3273 - acc: 0.8985 - val_loss: 0.5971 - val_acc: 0.8554\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.2907 - acc: 0.9140 - val_loss: 0.5876 - val_acc: 0.8618\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.2723 - acc: 0.9318 - val_loss: 0.6007 - val_acc: 0.8674\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.2010 - acc: 0.9502 - val_loss: 0.6334 - val_acc: 0.8688\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.1721 - acc: 0.9650 - val_loss: 0.6912 - val_acc: 0.8732\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.1481 - acc: 0.9752 - val_loss: 0.8658 - val_acc: 0.8638\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.1285 - acc: 0.9811 - val_loss: 0.9431 - val_acc: 0.8628\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.1066 - acc: 0.9877 - val_loss: 0.9324 - val_acc: 0.8682\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0981 - acc: 0.9895 - val_loss: 1.6670 - val_acc: 0.8058\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0933 - acc: 0.9902 - val_loss: 1.0011 - val_acc: 0.8704loss: 0.1005 - acc: 0.990 - ETA: 1s - loss: 0.1035 -  - ETA: 0s - loss: 0.1025 -\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0875 - acc: 0.9924 - val_loss: 1.1088 - val_acc: 0.8626 acc: 0.9 - ETA: 0s - loss: 0.0855 - acc:  - ETA: 0s - loss: 0.0885 - acc: 0.99\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0891 - acc: 0.9912 - val_loss: 1.9385 - val_acc: 0.7978\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0916 - acc: 0.9913 - val_loss: 1.1214 - val_acc: 0.8692\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0936 - acc: 0.9908 - val_loss: 1.1349 - val_acc: 0.8706s: 0.0902 - acc: 0.\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0887 - acc: 0.9917 - val_loss: 1.1298 - val_acc: 0.8706 0.9\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0871 - acc: 0.9924 - val_loss: 1.5390 - val_acc: 0.8444: 0.0844 - ETA: 0s - loss: 0.0848 - acc: 0.9\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0849 - acc: 0.9930 - val_loss: 1.1616 - val_acc: 0.8704\n"
     ]
    }
   ],
   "source": [
    "# 代码清单7-9 使用一个TensorBoard回调函数来训练模型\n",
    "\n",
    "callbacks = [keras.callbacks.TensorBoard(\n",
    "    log_dir = 'my_log_dir',\n",
    "    histogram_freq = 1,\n",
    "    embeddings_freq = 1,)]\n",
    "history = model.fit(x_train,y_train,\n",
    "epochs = 20,\n",
    "batch_size = 128,\n",
    "validation_split = 0.2,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c74a94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# P217\n",
    "# from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,to_file = 'model.png')\n",
    "\n",
    "# from keras.utils import plot_model\n",
    "plot_model(model,show_shapes = True,to_file = 'model.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2385ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P221\n",
    "from keras.models import Sequential,Model\n",
    "from keras import layers\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 3\n",
    "num_classes = 10\n",
    "model = Sequential()\n",
    "model.add(layers.SeparableConv2D(32,3,activation = 'relu',input_shape = (height,width,channels,)))\n",
    "model.add(layers.SeparableConv2D(64,3,activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "model.add(layers.SeparableConv2D(64,3,activation = 'relu'))\n",
    "model.add(layers.SeparableConv2D(128,3,activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "model.add(layers.SeparableConv2D(64,3,activation = 'relu'))\n",
    "model.add(layers.SeparableConv2D(128,3,activation = 'relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(32,activation = 'relu'))\n",
    "model.add(layers.Dense(num_classes,activation = 'softmax'))\n",
    "model.compile(optimizer = 'rmsprop',loss = 'categorical_crossentropy')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
